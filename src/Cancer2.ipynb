{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01853e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7176b71",
   "metadata": {},
   "source": [
    "# Load the standard packages for working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a5233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4024, 13)\n",
      "(4024,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>T Stage</th>\n",
       "      <th>N Stage</th>\n",
       "      <th>6th Stage</th>\n",
       "      <th>differentiate</th>\n",
       "      <th>Grade</th>\n",
       "      <th>A Stage</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Estrogen Status</th>\n",
       "      <th>Progesterone Status</th>\n",
       "      <th>Regional Node Examined</th>\n",
       "      <th>Reginol Node Positive</th>\n",
       "      <th>Survival Months</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>T2</td>\n",
       "      <td>N2</td>\n",
       "      <td>IIIA</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>35</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>T3</td>\n",
       "      <td>N3</td>\n",
       "      <td>IIIC</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>2</td>\n",
       "      <td>Regional</td>\n",
       "      <td>63</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>18</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>T2</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIB</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>3</td>\n",
       "      <td>Regional</td>\n",
       "      <td>41</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Alive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age T Stage  N Stage 6th Stage              differentiate Grade   A Stage  \\\n",
       "0   68       T1      N1       IIA      Poorly differentiated     3  Regional   \n",
       "1   50       T2      N2      IIIA  Moderately differentiated     2  Regional   \n",
       "2   58       T3      N3      IIIC  Moderately differentiated     2  Regional   \n",
       "3   58       T1      N1       IIA      Poorly differentiated     3  Regional   \n",
       "4   47       T2      N1       IIB      Poorly differentiated     3  Regional   \n",
       "\n",
       "   Tumor Size Estrogen Status Progesterone Status  Regional Node Examined  \\\n",
       "0           4        Positive            Positive                      24   \n",
       "1          35        Positive            Positive                      14   \n",
       "2          63        Positive            Positive                      14   \n",
       "3          18        Positive            Positive                       2   \n",
       "4          41        Positive            Positive                       3   \n",
       "\n",
       "   Reginol Node Positive  Survival Months Status  \n",
       "0                      1               60  Alive  \n",
       "1                      5               62  Alive  \n",
       "2                      7               75  Alive  \n",
       "3                      1               84  Alive  \n",
       "4                      1               50  Alive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.core.indexing import length_of_indexer\n",
    "df = pd.read_csv(\"Breast_Cancer.csv\")\n",
    "\n",
    "data = np.array(df)\n",
    "X = data[:,0:data.shape[1]-1]\n",
    "y = data[:, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f30cde",
   "metadata": {},
   "source": [
    "# Encoding Labels And Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29905fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12351d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-Stage: The T refers to the size and extent of the main tumor\n",
    "# N-Stage:  lymph nodes before they reach other parts of the body. \n",
    "# The N category can be assigned a letter or a number: \n",
    "# NX means there's no information about the nearby lymph nodes\n",
    "#6th stage: IIA, IIB, IIIA, IIIB, IIIC\n",
    "#Differentiate: Poorly differentiated, Moderately differentiated, Well differentiated\n",
    "#Regional or Distant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2014349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68 0 0 ... 23 0 60]\n",
      " [50 1 1 ... 13 4 62]\n",
      " [58 2 2 ... 13 6 75]\n",
      " ...\n",
      " [68 1 0 ... 10 2 69]\n",
      " [58 1 0 ... 10 0 72]\n",
      " [46 1 0 ... 6 1 100]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#enc = OrdinalEncoder().fit(X[:,1].reshape(-1,1))\n",
    "\n",
    "\n",
    "#enc.categories_=[[\"T1\",\"T2\",\"T3\"],[1, 2,3]]\n",
    "\n",
    "#X[:,1]= enc.transform(X[:,1].reshape(-1,1)).reshape(1,-1)\n",
    "\n",
    "\n",
    "# X = np.where(X ==\"T1\",1,X)\n",
    "# X = np.where(X ==\"T2\",2,X)\n",
    "# X = np.where(X ==\"T3\",3,X)\n",
    "# X = np.where(X ==\"T4\",4,X)\n",
    "\n",
    "# X = np.where(X ==\"N1\",1,X)\n",
    "# X = np.where(X ==\"N2\",2,X)\n",
    "# X = np.where(X ==\"N3\",3,X)\n",
    "\n",
    "# X = np.where(X ==\"IIIC\",5,X)\n",
    "# X = np.where(X ==\"IIIB\",4,X)\n",
    "# X = np.where(X ==\"IIIA\",3,X)\n",
    "\n",
    "# X = np.where(X ==\"IIB\",2,X)\n",
    "# X = np.where(X ==\"IIA\",1,X)\n",
    "\n",
    "# X = np.where(X==\"Undifferentiated\",1,X)\n",
    "# X = np.where(X ==\"Poorly differentiated\",2,X)\n",
    "# X = np.where(X ==\"Moderately differentiated\",3,X)\n",
    "# X = np.where(X ==\"Well differentiated\",4,X)\n",
    "# X = np.where(X==\" anaplastic; Grade IV\",4,X)\n",
    "# lb = preprocessing.LabelBinarizer(neg_label=-1, pos_label=0)  # Binary encoding\n",
    "# X[:,6] = np.abs(lb.fit_transform(X[:,6])).reshape(4024,)\n",
    "# lb = preprocessing.LabelBinarizer(neg_label=-1, pos_label=0)  # Binary encoding\n",
    "# X[:,8] = np.abs(lb.fit_transform(X[:,8])).reshape(4024,)\n",
    "# lb = preprocessing.LabelBinarizer(neg_label=-1, pos_label=0)  # Binary encoding\n",
    "# X[:,9] = np.abs(lb.fit_transform(X[:,9])).reshape(4024,)\n",
    "# lb = preprocessing.LabelBinarizer(neg_label=-1, pos_label=0)  # Binary encoding\n",
    "# y = np.abs(lb.fit_transform(y)).reshape(4024,)\n",
    "\n",
    "label_encoder_race = LabelEncoder()\n",
    "label_encoder_marital_status = LabelEncoder()\n",
    "label_encoder_t_stage = LabelEncoder()\n",
    "label_encoder_n_stage = LabelEncoder()\n",
    "label_encoder_6th_stage = LabelEncoder()\n",
    "label_encoder_differentiate = LabelEncoder()\n",
    "label_encoder_grade = LabelEncoder()\n",
    "label_encoder_a_stage = LabelEncoder()\n",
    "label_encoder_estrogene = LabelEncoder()\n",
    "label_encoder_progesterone = LabelEncoder()\n",
    "label_encoder_status = LabelEncoder()\n",
    "\n",
    "X[:,1] = label_encoder_race.fit_transform(X[:,1])\n",
    "X[:,2] = label_encoder_marital_status.fit_transform(X[:,2])\n",
    "X[:,3] = label_encoder_t_stage.fit_transform(X[:,3])\n",
    "X[:,4] = label_encoder_n_stage.fit_transform(X[:,4])\n",
    "#X[:,5] = label_encoder_6th_stage.fit_transform(X[:,5])\n",
    "X[:,6] = label_encoder_differentiate.fit_transform(X[:,6])\n",
    "X[:,7] = label_encoder_grade.fit_transform(X[:,7])\n",
    "X[:,8] = label_encoder_a_stage.fit_transform(X[:,8])\n",
    "X[:,10] = label_encoder_estrogene.fit_transform(X[:,10])\n",
    "X[:,11] = label_encoder_progesterone.fit_transform(X[:,11])\n",
    "\n",
    "y = label_encoder_status.fit_transform(y)\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a96e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_standard = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "698b745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y,test_size = 0.07, random_state=10, shuffle=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size = 0.07, random_state=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c04ee8a",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a211a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12fad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 23\n",
    "pca = PCA(random_state=SEED)\n",
    "\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_red = pca.transform(X_train)\n",
    "X_val_red = pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f24c6ae7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_pred_evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfit_pred_evaluate\u001b[49m(model, X_train_red, y_train, X_val_red, y_val, train_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Data - PCA\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Data - PCA\u001b[39m\u001b[38;5;124m\"\u001b[39m, graph_valutation_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fit_pred_evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "fit_pred_evaluate(model, X_train_red, y_train, X_val_red, y_val, train_label=\"Training Data - PCA\", test_label=\"Validation Data - PCA\", graph_valutation_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27733e52",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e470fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q18 - Accuracy on training data = 0.896264\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=100000000,max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_hat_logreg = logreg.predict(X_train)\n",
    "acc_logreg = logreg.score(X_train, y_train)\n",
    "print(\"Q18 - Accuracy on training data = %f\" % acc_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43be4d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q19 - w_logreg:  [[-0.02510384 -0.58014447 -0.51836302  0.20041227  0.35043914 -0.16892517\n",
      "   0.32470169  0.00719249 -0.39304342 -0.55056814  0.02799005 -0.08514777\n",
      "   0.06115714]]\n",
      "Q19 - intercept_logreg:  [0.03630279]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "w_logreg = logreg.coef_ \n",
    "intercept_logreg = logreg.intercept_ \n",
    "print('Q19 - w_logreg: ', w_logreg) \n",
    "print('Q19 - intercept_logreg: ', intercept_logreg) \n",
    "print(y_hat_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac0747",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80c4dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "svc = SVC(probability=False, C=1000, kernel=\"rbf\",verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53fd371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]...............................................................................................................................................................................*................................................................................................................................................................................................................................................*\n",
      "optimization finished, #iter = 415252\n",
      "obj = -728950.748982, rho = -3.615068\n",
      "nSV = 820, nBSV = 681\n",
      "Total nSV = 820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, verbose=20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3b48552",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_val = svc.predict(X_val)\n",
    "yhat_test= svc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "452efa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuaracy on the valdtion Data= 0.893130\n",
      "Accuaracy on the test Data= 0.893617\n"
     ]
    }
   ],
   "source": [
    "acc_val = np.mean(yhat_val  == y_val)\n",
    "acc_test= np.mean(yhat_test  == y_test)\n",
    "\n",
    "print('Accuaracy on the valdtion Data= {0:f}'.format(acc_val))\n",
    "print('Accuaracy on the test Data= {0:f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77d563c",
   "metadata": {},
   "source": [
    "# Nerual Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9236ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy.random as r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346093fa",
   "metadata": {},
   "source": [
    "# One-vs-all encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3bbed",
   "metadata": {},
   "source": [
    "### One-vs-all encoding\n",
    "Our target is an integer in the range [0,..,9], so we will have 10 output neuron's in our network.  \n",
    "\n",
    "-  If  $y=0$, we want the output neurons to have the values $(1,0,0,0,0,0,0,0,0,0)$\n",
    "\n",
    "-  If  $y=1$ we want the output neurons to have the values $(0,1,0,0,0,0,0,0,0,0)$\n",
    "-  etc\n",
    "\n",
    "Thus we need to change our target so it is the same as our hoped for output of the neural network.  \n",
    "-  If $y=0$ we change it into the vector $(1,0,0,0,0,0,0,0,0,0)$. \n",
    "-  If $y=1$ we change it into the vector $(0,1,0,0,0,0,0,0,0,0)$\n",
    "-  etc\n",
    "\n",
    "See page 29 from the website listed above\n",
    "\n",
    "The code to covert the target vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2ae283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43c66730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_v_train = convert_y_to_vect(y_train)\n",
    "y_v_test = convert_y_to_vect(y_test)\n",
    "print(y_train[0:4])\n",
    "print(y_v_train[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc1f8a",
   "metadata": {},
   "source": [
    "# Creating the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d52ce",
   "metadata": {},
   "source": [
    "### The activation function and its derivative\n",
    "\n",
    "We will use the sigmoid activation function:  $f(z)=\\frac{1}{1+e^{-z}}$\n",
    "\n",
    "The deriviative of the sigmoid function is: $f'(z) = f(z)(1-f(z))$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb1c7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def f_deriv(z):\n",
    "    return f(z) * (1 - f(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3da23",
   "metadata": {},
   "source": [
    "### Creating and initialing W and b\n",
    "We want the weights in W to be different so that during back propagation the nodes on a level will have different gradients and thus have different update values.\n",
    "\n",
    "We want the  weights to be small values, since the sigmoid is almost \"flat\" for large inputs.\n",
    "\n",
    "Next is the code that assigns each weight a number uniformly drawn from $[0.0, 1.0)$.  The code assumes that the number of neurons in each level is in the python list *nn_structure*.\n",
    "\n",
    "In the code, the weights, $W^{(\\ell)}$ and $b^{(\\ell)}$ are held in a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2529ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {} #creating a dictionary i.e. a set of key: value pairs\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1])) #Return “continuous uniform” random floats in the half-open interval [0.0, 1.0). \n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b99a96",
   "metadata": {},
   "source": [
    "### Initializing $\\triangledown W$ and $\\triangledown b$\n",
    "Creating $\\triangledown W^{(\\ell)}$ and $\\triangledown b^{(\\ell)}$ to have the same size as $W^{(\\ell)}$ and $b^{(\\ell)}$, and setting $\\triangledown W^{(\\ell)}$, and  $\\triangledown b^{(\\ell)}$ to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08279f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f9a59",
   "metadata": {},
   "source": [
    "## Feed forward\n",
    "Perform a forward pass throught the network.  The function returns the values of $a$ and $z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "390932ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(x, W, b):\n",
    "    a = {1: x} # create a dictionary for holding the a values for all levels\n",
    "    z = { } # create a dictionary for holding the z values for all the layers\n",
    "    for l in range(1, len(W) + 1): # for each layer\n",
    "        node_in = a[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l]  # z^(l+1) = W^(l)*a^(l) + b^(l)\n",
    "        a[l+1] = f(z[l+1]) # a^(l+1) = f(z^(l+1))\n",
    "    return a, z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca2eb9",
   "metadata": {},
   "source": [
    "## Compute $\\delta$\n",
    "The code below compute $\\delta^{(s_l)}$ in a function called \"calculate_out_layer_delta\",  and  computes $\\delta^{(\\ell)}$ for the hidden layers in the function called \"calculate_hidden_delta\".  \n",
    "\n",
    "If we wanted to have a different cost function, we would change the \"calculate_out_layer_delta\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64b3670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_out_layer_delta(y, a_out, z_out):\n",
    "    # delta^(nl) = -(y_i - a_i^(nl)) * f'(z_i^(nl))\n",
    "    return -(y-a_out) * f_deriv(z_out) \n",
    "\n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    # delta^(l) = (transpose(W^(l)) * delta^(l+1)) * f'(z^(l))\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3feb6",
   "metadata": {},
   "source": [
    "## The Back Propagation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63d67dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(nn_structure, X, y, iter_num=3000, alpha=0.25):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    N = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting gradient descent for {} iterations'.format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%1000 == 0:\n",
    "            print('Iteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(N):\n",
    "            delta = {}\n",
    "            # perform the feed forward pass and return the stored a and z values, to be used in the\n",
    "            # gradient descent step\n",
    "            a, z = feed_forward(X[i, :], W, b)\n",
    "            # loop from nl-1 to 1 backpropagating the errors\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], a[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i,:]-a[l]))\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                    # triW^(l) = triW^(l) + delta^(l+1) * transpose(a^(l))\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(a[l][:,np.newaxis]))# np.newaxis increase the number of dimensions\n",
    "                    # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                    tri_b[l] += delta[l+1]\n",
    "        # perform the gradient descent step for the weights in each layer\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            W[l] += -alpha * (1.0/N * tri_W[l])\n",
    "            b[l] += -alpha * (1.0/N * tri_b[l])\n",
    "        # complete the average cost calculation\n",
    "        avg_cost = 1.0/N * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "768bdb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(W, b, X, n_layers):\n",
    "    N = X.shape[0]\n",
    "    y = np.zeros((N,))\n",
    "    for i in range(N):\n",
    "        a, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(a[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4191c",
   "metadata": {},
   "source": [
    "## Running the neural network\n",
    "\n",
    "Our code assumes the size of each layer in our network is held in a list.  The input layer will have 64 neurons (one for each pixel in our 8 by 8 pixelated digit).  Our hidden layer has 30 neurons (you can change this value).  The output layer has 10 neurons.\n",
    "\n",
    "Next we create the python list to hold the number of neurons for each level and then run the neural network code with our training data.\n",
    "\n",
    "This code will take some time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4072130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 3000 iterations\n",
      "Iteration 0 of 3000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m nn_structure \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m13\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# train the NN\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m W, b, avg_cost_func \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_structure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_v_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36mtrain_nn\u001b[0;34m(nn_structure, X, y, iter_num, alpha)\u001b[0m\n\u001b[1;32m     13\u001b[0m delta \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# perform the feed forward pass and return the stored a and z values, to be used in the\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# gradient descent step\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m a, z \u001b[38;5;241m=\u001b[39m \u001b[43mfeed_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# loop from nl-1 to 1 backpropagating the errors\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(nn_structure), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36mfeed_forward\u001b[0;34m(x, W, b)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(W) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m): \u001b[38;5;66;03m# for each layer\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     node_in \u001b[38;5;241m=\u001b[39m a[l]\n\u001b[0;32m----> 6\u001b[0m     z[l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_in\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b[l]  \u001b[38;5;66;03m# z^(l+1) = W^(l)*a^(l) + b^(l)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     a[l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m f(z[l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# a^(l+1) = f(z^(l+1))\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a, z\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "nn_structure = [13,5,1]\n",
    "    \n",
    "# train the NN\n",
    "W, b, avg_cost_func = train_nn(nn_structure, X_train, y_v_train, 3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20058a6c",
   "metadata": {},
   "source": [
    "### Plotting the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085976ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the avg_cost_func\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0efa50",
   "metadata": {},
   "source": [
    "## Assessing accuracy\n",
    "Next we determine what percentage the neural network correctly predicted the handwritten digit correctly on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction accuracy and print\n",
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "print('Prediction accuracy is {}%'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e445388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first neural network with keras tutorial\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a17d4f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-macosx_10_14_x86_64.whl (244.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 244.3 MB 33.5 MB/s eta 0:00:01   |███▎                            | 25.2 MB 1.4 MB/s eta 0:02:39     |█████▎                          | 40.5 MB 248 kB/s eta 0:13:42     |██████▎                         | 47.6 MB 1.5 MB/s eta 0:02:15  | 58.7 MB 133 kB/s eta 0:23:06     |████████████▉                   | 98.1 MB 55.2 MB/s eta 0:00:03     |█████████████████▌              | 133.2 MB 42.2 MB/s eta 0:00:03| 207.5 MB 30.1 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.42.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.28.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 25.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (61.2.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.1.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.0 MB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 26.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.2 MB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[K     |████████████████████████████████| 439 kB 25.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 24.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-macosx_10_9_x86_64.whl (980 kB)\n",
      "\u001b[K     |████████████████████████████████| 980 kB 22.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.33.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 26.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.0.3)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 29.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/yaaqovshkifati/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: tensorboard-plugin-wit, tensorboard-data-server, protobuf, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.5\n",
      "    Uninstalling protobuf-4.21.5:\n",
      "      Successfully uninstalled protobuf-4.21.5\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.5.2\n",
      "    Uninstalling google-auth-oauthlib-0.5.2:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.5.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 2.10.0 requires protobuf<5.0.0dev,>=3.20.1, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 flatbuffers-22.11.23 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.11.0 libclang-14.0.6 opt-einsum-3.3.0 protobuf-3.19.6 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.28.0 termcolor-2.1.1\n"
     ]
    }
   ],
   "source": [
    "! python3 -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168df31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
